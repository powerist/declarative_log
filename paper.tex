\documentclass{article}

\usepackage{cite}
\usepackage{url}
\usepackage[normalem]{ulem}
\usepackage{color}

\begin{document}
\input{macro}

\title{Knowledge discovery in networked systems}
\author{}

\maketitle


\section{Project}
\label{sec:project}

\subsection{Motivation}
\label{sec:motiv}

Existing root cause analysis techniques assume the availability of a known
causality model. However, a network administrator may not have a complete
knowledge of all the causality relationships in the system (Examples?). In
certain cases, the only available information is the logging history of a
system. Therefore, a framework that allows the administrator to easily
create, update, manipulate and query dependency information is of great help. The
framework should also provide a friendly interface that fits the administrator's
high-level understanding of the system. In addition, the framework should also
enable the administrator to easily carry out root cause analysis, given the
dependency information and the logging history.

% \subsection{Goal}
% \label{sec:proj:goal}
% Help the user to define failure models of systems, so that the failure model
% could help identify the root cause of anomalies.

% Develop a declarative language that allows the user to specify/query the root
% cause of a system anomaly, so that the user does not need to handle low-level
% logging data directly.

\section{Meeting Log}
\label{sec:meetlog}

\subsection{5/27}

We discussed about the skeleton of the project. The problem is much clearer
after the meeting. The goal of the project, at this stage, is to develop a
declarative language that helps a network administrator to specify/query the root cause of a
system problem, given overwhelming log information.

\subsection{6/3}
\label{sec:meeting:63}

\paragraph{Progress}
\begin{itemize}
\item Read the paper ``A survey of fault localization techniques in computer
networks'': They summarized a number of techniques that find the root cause of a
system error with a given causality graph. 

\item Read the paper ``Efficient Querying and Maintenance of Network Provenance at
Internet-Scale'': They proposed a graph-based data structure to maintain network
provenance, i.e., dependency relationship. Also, different forms of
representation for specifying the causal relationship were given, such as
algebraic representation and BDD.

\item Scan through the NEC network data.
\end{itemize}

\subsection{6/9}
\label{sec:meeting:69}

We further discussed about the contributions we can make in our project. It now
seems that a promising direction is to explore efficient interactive causal
relationship generation. The causal relationship may be heterogeneous---that is,
the user can specify causal relationship at different level of granularity. Details can be found in 6/9 meeting slides.

Future steps:

\begin{itemize}
\item Related work survey: Does there exist any work that provides similar
  management?

A: Causality of an event can be modeled as a directed tree. A causality group is a set of
partial order, which can be represented as a DAG. The DAG can be implemented as
an adjacency graph, stored in a database.
\item Low-level operation of a command in the declarative language?

A:
\begin{itemize}
\item Insert($A \rightarrow B$): check if there is a path such that $B
  \rightarrow A$. If
not, add an adjacency link ($A \rightarrow B$) in the adjacent
graph. Otherwise, raise an error.
\item Delete($A \rightarrow B$): Delete the corresponding link in the adjacency
  graph.
\item Update($A \rightarrow B$ to $A \rightarrow C$): Delete($A \rightarrow B$)
  followed by insert($A \rightarrow C$).
\item Manipulate($A \rightarrow B$): Compose? Should also happen at the event level.
\end{itemize}

\item Details of the work flow: the steps the user could take to finish the
  modeling.
\item Connect SAF with ElasticSearch: decouple SAF from SQLite, and use restful
  api as the query language.
\end{itemize}

\paragraph{Meeting summary.}
In the meeting, we further clarified the problem.

In the current design, our framework takes two inputs:
(1) a set of logs from the network (format undefined); and
(2) a detected anomaly (format undefined).

The output of the framework is the root cause that could explain the detected
anomaly. The format of the root cause is also unknown now (could be an event or
a set of events). 

Within the framework, we have a library which stores behavior
models (i.e., causal relationship). There will also be a root cause analysis
engine that is responsible
for generating the root cause based on the anomaly, the logs and the
library. 
(\textcolor{red}{Root cause analysis engine is only used for case study.6/24}) 
\sout{A possible design for the root cause analysis engine
could be first to find the behavior models that have the anomaly as root---These
models are called failure models for the anomaly---then the
engine finds all log sequences satisfying the behavior model (we can
leverage \saf{} for this part), and runs the root cause analysis algorithm on
the log sequences found. }

The behavior library needs to be specified by the user (\textcolor{red}{or the
  domain-specific expert. 6/25}) ---it is almost impossible
to infer the behavior models without human input---and a language is needed for
the user to specify, manipulate, and query the library. \sout{The language could be any
existing language, such as \saf{} and Datalog, or a newly designed one.}

\paragraph{To-do}
\begin{itemize}
\item More survey on the root cause analysis is needed. The focus would be on
  (1) What's the current status of root cause analysis?; (2) whether anyone has
  tried to manage causality as a database? If so, how did they do it?
\item The real data is worth further exploration. Hopefully we can have more
  insight from the data.
\end{itemize}

\subsection{6/24}
\label{sec:meeting:624}

In today's meeting, I gave a survey on three commercial solutions for root
cause analysis through log
analytics---namely HP solution, CA technology solution and IBM solution. Among
the three solutions, HP solution provides guidance on the work flow
for root cause analysis. CA technology is similar to SAF, and their event rule
idea is helpful in our project. IBM solution, however, is closer to a
search-filter analytic tool, which allows the administrator to plot different
statistical graphs based on the logs. More details can be found on the slides
for the weekly meeting on June 24.

The design of the declarative language for our project was further discussed in
the meeting. The language should extend the design of SAF. In SAF, a behavior is merely
a set of events. This is not enough for a complex and heterogeneous computing
environment. In such an environment, users' knowledge of the system could vary among different
levels. For example, a domain-specific expert could be more familiar with a
certain types of devices, such as database servers or email servers, while a
network administrator could know more about the protocol-level information along with
topological information. Our language should provide the opportunity for
different users to specify their specific knowledge of the system, and manages these
knowledge effectively in the storage, so that root cause analysis can be
performed with these knowledge.


\paragraph{To-do}

\begin{itemize}
\item Detailed work flow of the user.
\item Connect SAF with ElasticSearch: decouple SAF from SQLite, and use restful
  api as the query language.
\item Survey on languages that allow the user to specify causality relationship
  on different granularity.
A: Ontology is an interesting concept. 
\end{itemize}

\subsection{7/1}
\label{sec:meeting:624}

In today's meeting, we clarify the work flow of performing root cause analysis
in a typical network, and the problem to be targeted at during my summer
internship. Additionally, we discussed about the next few steps of the project
towards our goal.

\begin{itemize}
\item {\bf Word flow.} The work flow of the root cause analysis is as follows:
  \begin{itemize}
  \item The user reports an abnormal symptoms to the network administrator. The
  abnormal symptoms include high latency or no response of a specific
  service. The user usually specify such symptoms informally, such as in natural
  languages.
  \item Next, the network administrator would start the root cause analysis by
  collecting log traces from all the devices in the network. Since devices could
  be manufactured by different vendors, the logs could be in a variety of forms.
  \item To allow for computer-aided log analysis, the network administrator should
  be able to convert logs of different formats into a unified one
  (e.g. relational database).
  \item With the unified log database, the network administrator should be
  able to specify the symptoms reported by the user rigorously. A failure symptom
  could be formally defined as a set of database entries, or events. 
  \item In addition to the symptom specification and the log traces, the network
  administrator still needs network provenance (i.e., dependency relationship
  between events or set of events) to help identify the root cause
  analysis. In the usual scenario of log analytics, the network provenance is not
  given beforehand. The network administrator needs to infer the provenance
  information based on his domain-specific knowledge, such as topological
  layout.
  \item The network administrator would then run the root cause analysis algorithm
  based on the given symptom and the provenance information to identify the root
  cause of the system anomaly. 
  \end{itemize}

\item {\bf Targeted problem.}
  The targeted problem scope of our project is the part of provenance knowledge
  maintenance. It is assumed that the log has been organized into a uniform format
  (e.g., relational database), and basic database queries are available (e.g.,
  through SQL language). The goal is to have a framework that allows the user to
  specify, query, validate and operate on semantic provenance --- The semantic level could
  be flexible \textcolor{red}{more clear on what semantic level means}.

  There are several requirements worth considering:
  \begin{itemize}
  \item The framework should be able to map the specified semantic provenance to
    corresponding low-level semantics, where the lowest-level semantics is the
    log traces. 
  
  \item The knowledge base should have categorization. For example, topological
    knowledge should be differentiated from protocol knowledge. Protocol
    knowledge could be reused across systems, but topological knowledge cannot.

  \end{itemize}

\end{itemize}

\paragraph{Future work}
Complete a root cause analysis case study on OpenStack.

\subsection{7/8}
\label{sec:meeting:678}

\paragraph{Thought}
I wonder if component-level dependency can also be specified in \saf{}. Because no
matter what dependency level we focus on, we still need to determine the
low-level logs by specifying the conditions over their fields. The higher level the
specification is, the more wildcard we are inserting into the specification.

For example, if we would like to specify a component-level dependency: $vm_1
\rightarrow vm_2$, we need to make it clear what logs are instances of $vm_1$
and $vm_2$. To do this, a candidate specification would be ``machine\_name =
$vm_1$''. This specification is still in the scope of \saf{}. Based on this, the
specification over the logs is similar to specification over the directory paths
in the file system.

\paragraph{Todo}

\begin{itemize}
\item Finish the manual root cause analysis case study.
\item Meanwhile, clarify the work flow of the user.
\item Find as much automation as possible in the work flow. For example,
  automatic model generation.
\end{itemize}

\subsection{7/29}
\label{sec:meeting:729}

In today's meeting, we discussed about the case study of Openstack logs. Based
on the discussion, further steps were proposed to continue the project.

\paragraph{Todo}
\begin{itemize}
\item Finish the case study of novadelete.
\item Re-do the case study on novaboot.
\item Develop back-tracking and forward-tracking utilities:
  back-tracking(event\_seed, model) = matched part of the model.
\item Develop component-level behavior model.
\item Develop NFA-based specification of behavior models.
\end{itemize}

\section{Root cause analysis case studies}
Manual root cause analysis case studies.

\begin{itemize}
\item Use SAF to analyze Openstack logs. All related files can be found under
  ``declarative-log-analytics/codebase/case_study/novaboot''.
  \begin{itemize}
  \item Identify the normal execution logs to explore: osloganal/data/logs/new\_testbed24/novadelete/delete-0.log
  \item Convert the log in JSON into an SQLite3 database. (done)
  \item Convert the log in JSON into an event sqlite3 database required by \saf{}.
    \begin{itemize}
    \item The schema of the database should satisfy the format of the event in
      \saf{}.
      
      As stated in ``SAF-trunk/plugins/p2db/eventattrs.c'' in p2db plugin of \saf{}: ``Each line of
      attribute is of the following format $\langle$attributename,
      attributetype$\rangle$ ... Each event specification must have the
      following attributes at a minimum "eventno integer", "eventtype text",
      "timestamp integer",	"timestampusec integer", "origin text" ''

      Bug: During the test of SAF, when the wildcard symbol---e.g.,
      port=\$1---is used in the behavior model, dependent events
      whose field values are 0 are not output by SAF. However, if the value of a
      field is explicitly designated as 0, dependent events will be correctly
      output.

      Fix: the problem lies in the file
      ``SAF-trunk/framework/common/sqlutils.py''. In line 76, SAF tests the
      validity of a value by ``if (newv):'', this causes the problem that when
      the value of a field is 0 in dependent events, it will not be
      processed. On the other hand, if the user explicitly specifies the value
      of the field as 0, SAF will convert the value into string ``0'', which
      is accepted by the conditional.
    \item The information extracted from JSON is of coarse granularity. Further
      parse values in the ``message\_body'' to extract OS\_UUID, OS\_IP and
      template id, and store them in the event table.(done)
      
    \item Sort the log information according to logs' timestamps. (The original
      log is already in the correct order)
    \end{itemize}

  \item Obtain domain-specific knowledge about OpenStack and the execution:
    data/models(Filtered Message Sequence)
  \item Understand syntax of \saf{} behavior models
    \begin{itemize}
    \item Read README files
    \item Read the source parser
    \end{itemize}
  \item Specify the domain-specific knowledge in SAF --- on different levels ---
    and found corresponding traces. (done with event-level behavior models)
    \begin{itemize}
    \item Level 1: event dependency
    \item Level 2: component dependency
    \end{itemize}
  \item \sout{Build the causality graph for different levels.}
  \end{itemize}
\item \sout{Root cause detection of failure symptoms based on the backtracking technique}
\end{itemize}

\section{Unsolved problems}
\label{sec:usp}

We list a number of identified but unsolved problems of the project.

\begin{itemize}
\item Results given by \saf{} do not always meet expectation. For example, if a
behavior model specifies chained dependency for a specific field, \saf{} does
not give a sequence of events, but returns the same event for each matched state
model.

\item In the log trace of boot-0.log, the message of template 17 and the message
  of template 15 share the same timestamp. This causes the log trace to match no
  template in the novaboot models. (17 and 15 should be reversed)

\end{itemize}

\section{Reading List}
\label{sec:read}

\begin{itemize}

\item Troubleshooting Blackbox SDN Control Software with Minimal Causal
Sequences. (link: \url{http://www.eecs.berkeley.edu/~rcs/research/sts.pdf})

\item Fault Management in Distributed Systems. (link:
\url{http://repository.upenn.edu/cgi/viewcontent.cgi?article=1960&context=cis_reports}) 

\item A survey of fault localization techniques in computer networks. (link:
  \url{http://www.eecis.udel.edu/~sethi/papers/04/socp04.pdf})

\item Root cause analysis in market products:

  \begin{itemize}
  \item The 4 Building Blocks of Root Cause Analysis
    (\url{http://apmdigest.com/the-4-building-blocks-of-root-cause-analysis}): The
    best practice is to unify the three layers into a single infrastructure
    management dashboard, so you can visually correlate all three levels of
    analytics in an efficient workflow.
  \item HP Operations Analytics (\url{https://www.youtube.com/watch?v=d3_r9-tFISk})
  \item Hui Zhang's email (6/15)
  \end{itemize}

\item Knowledge Discovery in Databases: An Overview 
(\url{https://mitpress.mit.edu/sites/default/files/titles/content/9780262660709_sch_0001.pdf})

\item Semantic Data Access to Relational Databases: IBM research
(\url{http://www.w3.org/wiki/images/9/90/Rdb2RdfXG$SeDA2RDB2RDFXG.pdf})

\end{itemize}

\section{\saf{}}
\label{sec:saf}

\subsection{Paper}
\label{sec:safpaper}

\paragraph{Overview.}
The purpose of \saf{}~\cite{arun2011} is to bridge the semantic gap between raw
data and the user's high-level view of the system. \saf{} achieves the goal by
introducing {\em behavior model} --- a logic-based abstraction that allows the user to
concisely specify desired relationship between different events of the system --- along
with a low-level implementation that maps user-defined behaviors (i.e., logic
formulas) to satisfying log traces. 

\paragraph{Implementation.}
The implementation is composed of five components: 
(1) knowledge base, which provides domain-specific knowledge pre-specified as behavior
models; 
(2) data normalizer, which normalizes data from different sources into unified
events --- an internal data model for storage and query.
(3) event storage, an SQL database storing events.
(4) analysis engine, which takes a user-specified behavior model as input, and
extracts the satisfying set of events (or event sequences) based on defined
semantics.
(5) presentation engine, an output system.

\paragraph{Comments.}
\begin{itemize}
\item Is the specification for exact time comparison useful? Due to possible
  clock shift between different devices in a distributed system, the timestamps
  in logs extracted from different devices may not be comparable at all. I
  believe relative time ordering makes more sense in a network.
\end{itemize}


\subsection{\saf{} Tool}
\label{sec:saftool}

\paragraph{Progress.}

\begin{itemize}
\item Tutorial finished: I have tried the example TCP records on the \saf
  website, and generated the traces that satisfy the three-way-handshake
  behavior.
\item Trying \saf{} on real-data now... (Detailed information of the data is in
  the email).
\end{itemize}

\paragraph{Questions:}


\subsection{A root cause localization model for large scale systems}
\label{sec:rootcause}

The paper (bib not found online) presents a model capturing essential features of the root cause
localization process. In the model, a system is modeled as a set of components
that interact with each other. Observable behaviors of the system are modeled as
quarks --- the smallest end-to-end observable unit of specific service. Each
quark is composed of:
(1) the set of components used by the quark (could be implemented as a list); and
(2) a health result, signifying the failure or the success of the quark. (could
be implemented as a boolean variable).

Partial failure is modeled with probability: Given a component $C_i$,
probability $p_i$ represents the failure probability of a quark that utilizes
component $C_i$.

The paper further defines the problem of root cause localization, which has two
versions: deterministic version and statistical version. Only the deterministic
version is relevant to our project: Given several quarks of the system, some of
which succeed and others fail, estimate the set of components that could have partial
failure i.e., list of components $C_i$ with $p_i > 0$.

\paragraph{Comments}

\begin{itemize}
\item Is failure always modeled using probability? What are other possible
  failure models?
\end{itemize}



\bibliography{paper}{}
\bibliographystyle{plain}

\end{document}
%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
